[{"categories":null,"contents":"   BANCO - A crude bank backend API  Project Link\n   FUNCTIONALITY   Create User in the banco system  Each user can create multiple accounts, but accounts must have different currency Only user, authenticated into banco system can manage their accounts(create, list, update, delete - CRUD)   Transactions - money can be transferred from one user account to other  To perform transaction, user must be authenticated into banco system User can only send money from their account Transaction can only take place between accounts of same currency Each transaction is consistent       DB design/architecture     TECHNICAL DETAILS   Database setup scripts in scripts/db.sh SQLC to generate models and crud code golang-migrate for migrations environment variable setup in makefile (best practice) Nice way to implements DB transaction for money transfer  transaction lock and deadlock handling while updating user account balances For each transaction transfer details are stored in transfer table(fromAccount, toAccount, amount) Two entries created in entry table, how much money got added/deducted from toAccount and fromAccount Update account balance of fromAccount and toAccount   Testing  Unit tests Integration tests testing via mocking (dependency injection - db layer is injected into api layer) go-mockery is used for mocking Test containers are used to run integration tests There is no service layer, as it seems to be a little overkill for this project.   In api request - custom param validator (used reflection) User password encryption using bcrypt Use Paseto based user authentication  JWT authentication code is also present Interface is used for Token based authentication So, you can easily replace Paseto with JWT   Github Actions is used as Pipeline Docker and docker compose setup Pushing latest images to digital oceans private registry on push  ","date":"Oct 05","permalink":"https://rahilrehan.github.io/projects/a_project/","tags":null,"title":"Banco"},{"categories":["concepts"],"contents":"This is my notes from book reading the book Hands on software engineering with Golang and all the credits go to the Achilleas Anagnostopoulos\n   Go Vendoring  Also called lazy package resolution is using immutable snapshot of dependencies whenever a Go application is compiled. i.e having a copy of dependencies cached, which will be used for compilation.\nWhy vendoring? Behavior of application might change when dependencies are updated to newer versions automatically.\n  Approaches\n Fork dependency with particular version and point import to it create a manifest file which will list all the dependency versions cache dependencies to vendor folder(checked into vcs)    Advantages:\n can create LTS releases serves as a safety net in case an upstream dependency suddenly disappears from source (ex: left-pad)    Disadvantages:\n People often do not periodically update them. Some important fixes and issues resolved in dependencies are not reflected in the application. (Security issues?)    How to vendor?\ngo mod vendor    Go testing  As application complexity grows overtime, it becomes very important to have comprehensive tests.\nUnit test: a unit is the smallest possible bit of code that we can test. functions, structs, methods and even Go packages can be considered as single unit.\nStub: A stub is the simplest test pattern that we can use in our tests. Stubs typically implement a particular interface and don\u0026rsquo;t contain any real logic; they just provide fixed answers to calls that are performed through the course of a test. ( Ex: Chapter04/captcha)\nSpy: A spy is nothing more than a stub that keeps a detailed log of all the methods that are invoked on it. For each method invocation, the spy records the arguments that were provided by the caller and makes them available for inspection by the test code. ( Ex: Chapter04/chat)\nMocks: Contrary to the fixed behavior exhibited by stubs, mocks allow us to specify, not only the list of calls that the mock is expected to receive but also their order and expected argument values.\nIn addition, mocks allow us to specify different return values for each method invocation, depending on the argument tuple provided by the method caller. Writing mocks from for all objects is very tedious, so often use mock generation tool.\n GoMock Creates mocks based on interfaces definitions, leverages reflection. ( Ex: Chapter04/dependency)  Fake objects: fake objects also adhere to a specific interface, which allows us to inject them into the subject under test. The main difference is that fake objects do, in fact, contain a fully working implementation whose behavior matches the objects that they are meant to substitute. ( Ex: Chapter04/computer)\nBlack box testing: Test the exposed public interface, functions and variables of the package (exported when anything starts with capital letters). Test package name can be changed to package_test, this will help in testing the package as an external entity.\nWhite box testing: Testing implementation details or code which is not public, (all the things which start with small letters). We can name our file as package_internal_test and test package name can be same as package under test, so that the internal entities are accessible.\nTable Driven testing + Sub testing: Contains two parts: (test case definition and test-runner code).\nAll the duplicate setup can be stored in test case definition. And logic can be modified accordingly in test-runner. We can use anonymous struct to create test case definition of different scenarios.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  // table driven design of test cases scenes := []struct { testName string inputArg int expected int }{ {\u0026#34;valid test\u0026#34;, 3, 9}, {\u0026#34;invalid test\u0026#34;, -1, 1}, } // sub testing for test in scenes{ t.Run(test.testName, func(t *testing.T){ //test code  }) }   Checkout, testing library: Testify It provides, Assertion, mocking, suite interfaces and functions.\nRequire vs Assert? The require package provides same global functions as the assert package, but instead of returning a boolean result they terminate current test when test fails.\nIntegration tests: ensures that different units (or services, in a microservice architecture) interoperate correctly.\nAlso, as part of integration tests, you might need to connect with a real database. Just to make the configuration and our life easier, we can use TestContainers\nBefore trying to write lot of integration tests, make sure you have good number of concrete unit tests in-place.\nFunctional tests: Used to verify end-to-end correctness by simulating a user\u0026rsquo;s journey through the system. They ensure that the complete system is working as expected and involve multiple complex actions involving multiple system components.\nSmoke tests: Or build acceptance tests constitute a special family of tests that are traditionally used as early sanity checks by QA teams before going for functional testing.\nIf smoke tests fail, no further testing is performed. They must be quick and only check for basic acceptance criteria, in-depth testing can be done by functional tests at later stage.\nChaos testing: key point behind chaos testing is to evaluate your system\u0026rsquo;s behavior when various components exhibit different types of failure. Idea is to have a preventive fashion mechanism rather than trying to react on failure.\nUsing ambassador/sidecar pattern, you can inject failures into the system like latencies/ lags/ traffic etc.\nTesting Techniques\nUse environment variables to run tests as required. Example, DB url can change according to testing/staging/prod environments.\n1 2 3 4  // skipping tests if host == \u0026#34;\u0026#34; { t.Skip(\u0026#34;Skipping test as DB connection info is not present\u0026#34;) }   Run tests faster:\n -short flag to go test, Use Short helper function to get the flag value and based on this you can skip some tests. -failfast, used to abort all tests if there is a failing test -timeout flag, to define timeout. Default is 10 mins. If set to 0, no time limit is defined.  Exclude test and components: Using build tags helps to decide whether a particular Go file in a package should be passed to the Go compiler.\nBuild tags appear at top of package, a new line is required after build tag line. Space between tags to represent or, comma to represent and and ! to represent not.\nWe can use build tags in both test(go test) and build(go build) Ex: +build unit_tests all_tests +build integration_tests all_tests +build e2e_tests all_tests Chapter04/buildtags\nMore tricks? Mocking calls to external binaries (Chapter04/pinger) and testing timeouts (Chapter04/dialer)\n","date":"Nov 06","permalink":"https://rahilrehan.github.io/post/hands-on-se-with-golang/","tags":["golang"],"title":"Book Notes - Hands on Software Engineering with Golang - 01"},{"categories":["concepts"],"contents":"   GO env variables:  These are some go env variables\n GOROOT  Location of GO SDK    1 2 3  export GOROOT=~/Downloads/go export PATH=$PATH:$GOROOT/bin     GOPATH (for go version greater than 1.13) i.e using with GO modules\n downloaded source code is stored in $GOPATH/pkg/mod compliled binaries are stored in $GOPATH/bin  we can change this behaviour with $GOBIN   defaults to $HOME/go    GOBIN\n this is where all compiled binaries will be stored if we set this, we can run binaries without specifying full path    Run go env to list all go related environment variables\n   Go commands   go mod init github.com/RahilRehan/banco, Creates a go.mod file go install, compiles and place binary in $GOBIN go build, compiles and places binary in current directory go run main.go, compiles and executes the binary  go run cmd/*.go, if main package contains multiple files       Go packages   go packages is way to organize code and also helps in code reusability every go file starts with package package_name  ex: package main   all go files with same package name are placed in same directory     Dependency management in Go    collection of packages(nested pacakages may exist) forms a Go module\n  there are go.mod and go.sum files is present in modules root\n  go.mod contains modules import path and list of dependencies\n if a direct dependency does not have go.mod internally, its dependencies are imported as indirect dependencies in projects go.mod file.    go.sum contains\n list of checksum of all direct and indirect dependencies with versions. this checksum is used to validate none of the dependencies got modified.    alias:\n Import packages with different names: import config demo-app/repo/configuration Blank import is used to just run init function of package, ex: import _ sql/pq    init function:\n Used to initialize global variables of a package. Executed when the package is initialized.      go get package_name - downloads a dependency to current project, and adds it to go.mod\n  go mod tidy - makes sure the current projects dependencies reflect go.mod file and vice versa\n  go mod download - downloads dependencies listed in go.mod\n  go mod vendor - bundles all dependencies in vendor folder, reduces downloading dependencies\n  import paths:\n import pacakge within same module: import module_name/package_name in go.mod file use replace package_name =\u0026gt; new_package_name to replace a package.(useful)    semantic imports\n semantic versionning: V.{major}.{minor}.{patch} Go automatically picks up latest from minor and patch versions For using particular major version in imports, append major version to end of dependency , ex: import \u0026quot;github.com/javascript/v8\u0026quot;    Notes\n semi colon is not requried at the end of statements in go       Variables   Using var keyword(very explicit:  var variable_name type, ex: var name string. All declared variables are assigned zero value of given type. Multiple variable declaration: var one, two, three int64 Declaraion + Assignment: var one, two int64 = 1, 2 declaration block with multiple types    1 2 3 4 5  var ( name string age int64 vaccinated bool )    Type inferred declaration and initialization:  var a = 5, var name = \u0026quot;Alice\u0026quot; type of the variable is automatically inferred from right hand side   Short-hand declaration and initialization  a := 5, name := \u0026quot;rahil\u0026quot; note that we can only use this type of declaration inside function for reassigning we cannot use :=, = must be used   Any unused variables in code will cause compilation error Local variables are one which are defined at function or block level  Scope and lifetime of these variables until these blocks are in use   Global variables are declared outside functions and blocks  they are declared at package level If they start with capital alphabet, they are exported to other packages If they start with small alphabet, they are not exported to other packages       Constants   Once declared, we cannot change the value  1 2 3 4 5 6 7 8 9 10  //single const a string = \u0026#34;random\u0026#34; const b = \u0026#34;inferred type\u0026#34; //multiple const ( E = \u0026#34;Exported\u0026#34; n = 23 )    const values must be known at compile time, so we cannot declare const from a functions return value const are also scoped, i.e if const name start with caps only then its exported out of package and, if declared inside function cannot be accessed in other functions. four types of constants: int, string, character(int32), bool     Datatypes   Basic Types  Integers  ex: var num int64 = 189 Int64 (Signed) -\u0026gt; 64 bits =\u0026gt; 8 bytes Uint64 (Unsigned) -\u0026gt; 0 to 2^64 - 1 numbers can be stored also, there are int8, int16, int32 and similarly for uint unintptr, can hold pointer of any size   Float64 and Float32 for precision based operations  ex: var f float64 = 3.56   Complex64, Complex128  ex: var c complex64 = 9 + 3i   Byte  ex: var mychar byte := 'r' same as uint8 value between 0 - 255 can represent ASCII values   Rune  ex: rPound := '£' same as int32 used to represent Unicode points  Unicode points are superset of ASCII Unicode points can assign a number to any character in existence UTF-8 stores every Unicode Point either using 1, 2, 3 or 4 bytes     String  ex: var name string=\u0026quot;Alice\u0026quot; Slice of bytes, i.e array of bytes string is usually represented in utf-8 format therefore, according to the character type in string, the size varies between 1-4 bytes.   Boolean (true of false)  ex: var isGood bool = true         More types   Pointer  you can declare pointer with new keyword or with \u0026amp; * is the dereferencing pointer, using * we can access and change value pointed by the pointer. lot of different things can be done once we start coupling both * and \u0026amp; default value of pointer is nil    1 2 3 4 5 6 7 8  a := new(int) *a = 10 fmt.Printf(\u0026#34;Address of int is %d and value is %d\u0026#34;, a, *a) b := 2 c := \u0026amp;b *c = 100 fmt.Println(\u0026#34;Address of b is %d and value of b is %d\u0026#34;, c, *c)    Struct  is a collectin of data of different types fields can be accessed and set using . empty structs or partial structs can be created while creating new variables from struct, you need not provide field names , is required for seperation of fields while creating struct variables It is possible create pointers to struct variables using \u0026amp; or new keyword we can directly change field values using pointer two ways to print structs, using fmt package or using encoding/json package. struct tags: used to add meta data to struct, can be used while encoding/decoding into different forms Nested structs are possible, mainStruct.nestedStruct.fieldName to access nested structs field Only struct which starts with caps are exported, same for struct fields. Struct equality:  struct will be only equal if fields and values are same also, fields needs to compatible for equality to work slice, map and func are not supported/compatible to check equality   new copy of struct is created when  struct variable assigned to other variable struct variable passed into a function to save memory, use pointer whenever possible      1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  type employee struct { name string age int salary int } //empty struct variable a := employee{} //non empty struct b := employee{name: \u0026#34;noname\u0026#34;, age:90, salary:0} //without field names c := employee{\u0026#34;noname\u0026#34;, 90, 0} //access field fmt.Println(\u0026#34;name is %s\u0026#34;, b.name) //set field b.name = \u0026#34;myname\u0026#34; sp := \u0026amp;b (*sp).name = \u0026#34;anothername\u0026#34; sp.name = \u0026#34;anothername\u0026#34; //also works    Array  0 index based arrays Arrays are values in go, that means there is no concept of pointer pointing to first element of array we can iterate array using normal for loop or for range loop. Size is fixed in arrays    1 2 3 4 5 6 7 8 9 10 11 12 13  arr := [size]{type}{a1, a2... an} arr2 := [...]int{2, 3} //length is equal to no of elements arr3 := [4]int{1,2} //rest of values are 0\u0026#39;s i.e zero value of type  //access arr2[0] //assign arr[1] = 3 //multiple element access possible, returns a copy in range arr[index:] arr[:index] arr[:] //copy of entire array    Slice  Unlike array, slice is like a struct which points to an underlying array. Length of slice is no.of elements in slice. Capacity of slice is the max capacity that internal array can hold. make can also be used to create slice new can also be used    1 2 3 4 5 6 7 8 9 10 11 12  //creation s := []int{1, 2} fmt.Println(len(s), cap(s)) //creating slice from other slice or array arr := [4]int{1, 2, 3, 4} sl := arr[1:3] //slice from array, len=2, cap=3 sll := sl[:] //slice from another slice  numbers := make([]int, 3, 5) //create using make, the later params are length and capacity  multiDim := [][]int{{1, 2, 3}, {3, 4, 5}}   - to append elements to slice: `func append(slice []Type, elems ...Type) []Type` - internal size of will increase as slice length exceeds capacity - unlike structs, for slices copies are not created on assigning slice to other variable. i.e they are referenced - use `copy` function to perform copy of slice `func copy(dst, src []Type) int` - default zero value of slice is `nil`   Map  dictionary / hashmap in go search, insert, retrieve, delete in O(1) Apart from Slice, Map, Function other types can be used as keys in map Any type can be used as values in map declare a map using map[key_type]value_type using make =\u0026gt; make(map[string]int) zero value of map is nil map is reference type, so assigning to other variable refers to same map maps are not safe for concurrent use, use locks for concurrent access.    1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  // access m[key] //assign/create/modify m[key] = value //delete delete(map, key) //check if key exists val, ok := m[key] len(m) //to get length of map  for k, v in m{ //iterate over map \tfmt.Println(k, v) }    IOTA  similar to enums    1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  //without iota const ( a = 0 b = 1 c = 2 ) //with iota const ( a = iota b c ) //skip value in iota const ( a = iota _ b c ) //iota operations const ( a = iota b = iota + 4 c = iota * 4 )      Functions  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  // signature func name_of_function(param1 int, param2 string) (int, int){ a, b := 1, 2 return a, b } // if parameters are of same type, we can club them into one func name_of_function(param1, param2 string) (int, int){ a, b := 1, 2 return a, b } //named returns, useful when function returns error func returnAandB()(a, b int){ a, b = 1, 2 return }     Functions are also type in Go and, Higher order functions are supported. So, we can..\n return functions from other functions. pass functions as parameter to other functions. assign function to a variable(anonymous functions) create function types(declare a type with function signature)    Go also supports function closures!\n Consider, function b which lives inside another function a. From below example, the inner function b can access the counter variable even though it got returned. And the copy of counter vairable is unique to each function returned from a This is called closure    1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  func a() (b func() int){ counter := 0 b = func () int{ counter += 1 return counter } return } func main() { b := a() fmt.Println(b()) fmt.Println(b()) c := a() fmt.Println(c()) fmt.Println(c()) } //output 1 2 1 2    Immediate invocation is possible, i.e add () at the end of function definition to invoke it. Variadic Parameters  func add(numbers ...int)  pass any number of int params to add function numbers is an array of ints add(1, 2, 3, 3, 4, 5, 6), this is how we can call it, and params can vary in length         Methods   Attaching functions to types func (r receiver_type) func_name(args) returns This will let us emulate object oriented behavior, where types can have functionality attached to them Very similar to calling methods on objects Using pointer receivers will decrease memory usage and we will also be able to change values from method.  i.e we can emulate setters   Reciever types must be defined in the same package If we have nested struct, we can directly call method attached to nested struct If method names begin with caps then they are exported out of package, but then type also must be public.     Loops   there is no while loop in go there are only two types of loops,  for loop for range loop  can be used to iterate over array, slice, string, map and channels using range keywords return two values =\u0026gt; index and value we can ignore second return by using a _ or just using one variable on left hand side     break and continue statements work just as in any other programming language labels and goto are also present in golang, to go to particular label from any point in program  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50  // for initialization; condition; post_statement{} for i:=0; i \u0026lt; 5; i++ { fmt.Prinlnt(\u0026#34;yello!\u0026#34;) } // emulate while loop i := 0 for i\u0026lt;5{ fmt.Prinlnt(\u0026#34;yello!\u0026#34;) i++ } // for range loop on array arr := []int{1, 2, 3, 4} //array for index, value := range arr{ fmt.Println(index, value) } // on string: we should use range loops on strings as UTF-8 encoded sample := \u0026#34;a£b\u0026#34; for idx, letter := range sample { fmt.Println(idx, letter) } // on map func main() { m := map[string]string{ \u0026#34;name\u0026#34; : \u0026#34;john\u0026#34; , \u0026#34;vehicle\u0026#34; : \u0026#34;car\u0026#34;, } for key, value := range m{ fmt.Println(key, value) fmt.Println(m[key]) }\t} // on channels, example taken from \u0026#34;golangbyexample.com\u0026#34; func main() { ch := make(chan string) go pushToChannel(ch) for val := range ch { fmt.Println(val) } } func pushToChannel(ch chan\u0026lt;- string) { ch \u0026lt;- \u0026#34;a\u0026#34; ch \u0026lt;- \u0026#34;b\u0026#34; ch \u0026lt;- \u0026#34;c\u0026#34; close(ch) }      Conditional statements   if/else statements  1 2 3 4 5 6 7  if condition { //Do something } else if condition { //Do something } else { //Do something }   - there are no shorthand if/else in go - there are no ternary statements in go - if with initialization statement, you can declare variables in if statement and those variables are scoped to that particular if block. You can even call function in initialization statements.  1 2 3 4  if a:= 6; a \u0026lt; 10{ fmt.Println(\u0026#34;less than 10\u0026#34;) }    switch statements  break statements are not required fallthrough to also check more cases after a case match    1 2 3 4 5 6 7 8 9  switch statement(pre); expression { case expression1, expresstion2: //Dosomething \tfallthrough case expression2: //Dosomething \tdefault: //Dosomething }      defer   helps in deferring some activity used for cleanup activities example if you open a file, you must close it. But we often forget it! in Go, you can defer the required things before main logic. if we have multiple defers statements, they will run in reverse order at the end of function. inline defers, anonymous functions which will run at end of function defer itself is implemented internally with stack defer function are executed even if the program panics  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  func write() error { file, err := os.Open(\u0026#34;temp.txt\u0026#34;) if err != nil { return err } defer file.Close() // this will execute at the end of function, executed second(i.e after below defer) \tdefer func(){fmt.Println(\u0026#34;closing file..\u0026#34;)} // first defer to be executed  n, err := file.WriteString(\u0026#34;text.....\u0026#34;) if err != nil { return err } fmt.Printf(\u0026#34;Number of bytes written: %d\u0026#34;, n) return nil }      Interfaces   Interface is a type in Go which is a collection of method signatures With this you can achieve duck typing in Go. i.e we check if some attributes and methods are present. The main reason why we must use interfaces is because we can mock them and hence testing becomes easier. A type imlicitly implements interface if it implements all methods in interface.  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43  type Animal interface { walk() eat() } type dog struct { age int } func (d dog) eat() { fmt.Println(\u0026#34;dog eats\u0026#34;) } func (d dog) walk() { fmt.Println(\u0026#34;Dog walks\u0026#34;) } func (l lion) eat() { fmt.Println(\u0026#34;Lion eats\u0026#34;) } func (l lion) walk() { fmt.Println(\u0026#34;Lion walk\u0026#34;) } func callEat(a Animal){ a.eat() } func main() { var a Animal fmt.Println(a) //nil interface =\u0026gt; zero value  a = dog{age: 10} a.eat() a.walk() callEat(a) a = lion{age:24} callEat(a) l, ok := a.(lion) //determine type of interface }    In the above example, dog imlements the Animal interface. We can have other types as well which may implment Animal interface. We can assign any variable types which implement an interface to interface variable. We can also pass any variable types which implement an interface to function accepting that interface. Interfaces help in writing more modular and decoupled code. Functions which accept interfaces becomes very generic to use. pointer reciever vs value reciever  if we use pointer as reciever then both variable and pointer to the variable of that type can be used while assigning to interface or while passing to a function which accepts an argument as that interface. if we use pointer as reciever then the only pointer to the variable of that type can be used while assigning to that interface or while passing to a function that accepts an argument as that interface.   A type can implement multiple interfaces. Zero value of interface is nil. Nested interfaces / embedded interfaces are possible. Then type must implement all methods from main interface and nested interface.  1 2 3 4 5 6  //embedded interface type ReadWriter interface { Reader Writer }    It is also possible to have interface in struct. Whenever we create instance of that struct we must pass an object to interface field which implements all methods of that interface. An empty interface has no methods , hence by default all types implement the empty interface.     Goroutines   lightweight threads with own execution context which can run concurrently with other goroutines. Concurency is achieved using goroutines in Go. Running goroutine is simple as just adding go keyword before invoking any function Goroutine functions are run asynchronously, so the next statements execute immediately and does not wait for goroutine to complete execution. Main function - is the main goroutine, which spawns other goroutines.  when main goroutine exits, program also exits and other goroutines may not even get executed.   Read more abour run queues in go here  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  //example func threadSpawner(id int) { fmt.Println(id) } func main() { fmt.Println(\u0026#34;Start\u0026#34;) for i := 0; i \u0026lt; 10; i++ { go threadSpawner(i) } time.Sleep(time.Second * 2) fmt.Println(\u0026#34;Finish\u0026#34;) } // anonymous goroutines go func(){ //body }(args..)      Channels   Channels provide communications and synchrounization between goroutines. Channels internally manage locks as well. They act like pipes, you can perform only two actions. Send to channel, Recieve from channels.  1 2 3 4 5 6 7 8 9 10 11  func main() { var ch chan int ch = make(chan int) //send into channel  ch \u0026lt;- 5 //recieve from channel  val := \u0026lt;- ch }   ","date":"Oct 23","permalink":"https://rahilrehan.github.io/post/golang-snippets/","tags":["golang"],"title":"Golang quick reference"},{"categories":["concepts"],"contents":"   What is Software Development/Engineering?  Software engineering is defined as the application of a systematic, disciplined, quantifiable approach to the development, operation, and maintenance of software. - IEEE\u0026rsquo;s Standard Glossary\nSoftware devlopment is not just writing code, its about writing clean, understandable and maintainable code. And there are many other things involved in software development process. Things like requiremnt gathering, planning, desinging, testing, releasing and later maintaining. These aspects are also very important!\nLike Martin Fowler said, “Any fool can write code that a computer can understand. Good programmers write code that humans can understand.”\n   Types of software engineers:  SDE(Software development engineer) - A common term used to represent an umbrella of professions.\n Frontend engineers: Folks who deal with visual components of the product. Backend engineers: Folks who deal with internal system components providing an abstraction in form of APIs which frontend engineers can use. Fullstack engineers: Combination of both of the above roles. System Architect: The system designer, makes sure the systems design is good . SDET(tester): One who test the whole system for bugs and acceptance critereas.  In some companies testing is part of development process, so this role is played by SDE itself. Ex: in TDD   Operations engineer: Deals with releasing the product to market. Deployment and stuff. SRE - Site reliability engineers: Folks who work both on development teams and operations teams(release teams) Devops engineer: Acts as a middleman between devolopment teams and operations team. It\u0026rsquo;s more of a culture. So, some companies may not have this role at all.     Testing   Acceptance tests: end-to-end tests to ensure the whole system adheres to business requirements. Performance, Load, Regression testing: Even though all the test cases pass, system has to be performant, should be able to handle load etc. These tests evaluate above metrics.     Software Development Models:     Waterfall model:  Steps in waterfall model:\n Requirement collection (customer requirement) Desgin (design system accordingly) Implementation (build system) Verification (verify if the product meets the initial requriements) Maintenance (Maintain the project)  In this model we assume that all requirements are collected before implementation (which is almost never the case!)\n   Iterative Model:  Steps in iterative model:\n Requirement collection Design Implement Verify Jump to 1st step(and repeat)   Repeat this until the customer is satisfied ^^ Problem from waterfall model is solved!     Agile!   Agile itself is not a model, it is an umbrella term. Agile way says,  we have to build software in iterative, incrementing, short cycles. Intra-team(cross-team) communication is key to reduce conflicts in future.       Some models of agile:     Lean development:[copied from wiki]   Eliminate waste : do not add anything which is not required. Amplify learning: gather requirments constantly, share knowledge among teams. Decide as late as possible: conter-intuitive? nah, just don\u0026rsquo;t commit early. Deliver ASAP: the faster the deliver, the faster the feedback and faster the cycle repeats. Empower the team: Important. Optimize the whole: Always think about how the system works on the whole.     SCRUM!!   The whole project is broken down into chunks. Each chunk is divided such that it can be completed in 2-4 weeks. And this timeframe to complete a chuck is called sprint. Each chunk of work is again divided into tasks which people can pickup and complete. Number of tasks completed in a sprint gives teams velocity. Balance the velocity, it shouldn\u0026rsquo;t be too high(easy tasks) or too low(hard tasks). The tasks which are not completed(spillovers) are again put into next sprint. Scrum events:  Planning - Initial planning of whole project Estimation - Splitting into chunks Daily standups - Daily updates(what was done yesterday, what will be done today, any blockers?) - each team member talks about these three points in short. Retrospection - After each sprint, what went well and what can be improved must be discussed among team. And actions items have to be planned accordingly.       Kanban   A board style todo-list. Contains lanes  TODO/Backlog Doing Review Done   More lanes can be added according to teams need and style Ex: Trello     Devops!   Popular! People are switching to microservice architecture. As number of services increase in microservice architecture, each team which is responsible for a service owns the service. Hence, team should also be involved in operations related tasks! Devops itself has become a new role now-a-days. It was just a culture before\u0026hellip;  ","date":"Oct 18","permalink":"https://rahilrehan.github.io/post/software-engineering-lifecycle/","tags":["software engineering"],"title":"Software Development Lifecycle"},{"categories":["concepts"],"contents":"   Basics   Spring has lot of modules start.spring.io lists many spring modules which you can configure spring boot is useful to build RESTfull web services. It makes developing spring applications easy by auto configuring default components. It is opinionated framework fat jar -\u0026gt; also includes tomcat. better solution if you want to deploy on cloud platforms     Dependency Injection   Assume mail sender example, where we can have mailSender of type SMTP, POPM or MockMail. We can have an interface MailSender which defines the common functionality and we implement the interface in SMTP, POPM or Mock class. **Problem: object creation will be like: **  private MailSender = new SMTPMailSender() private MailSender = new POPMMailSender() private MailSender = new MockMailSender() we need to hardcode the type while creating object can we automate this? Add @Component annotation to any class which implements MailSender Add @Autowired annotation when creating object how does it work:  When application starts all the beans gets setup  Beans: annotations at top level, whose object will be created and stored in Application Context Beans examples: @Component, @RestController   When application is running and when we create objects variables for which we have annotations like @Autowired. Objects which were already created from application context are assigned to current variables. i.e those objects from application context are injected into these variables and hence dependency injection     @Autowired also works on methods(setters, constructors, getters, any methods..) Multiple beans problem: when we create two classes from same interface and add @component annotation to both classes, and create object using interface using @autowired annotation, spring will be confused to choose between beans  one solution is to use camel-case variable names while creating objects which resemble the name of the class you want (ex: smtpMailSender) you can also add name param to @component -\u0026gt; @component(\u0026ldquo;mockMail\u0026rdquo;), and create object using the name mockMail use extra @primary annotation, the bean which has this will get preference you can also use @qualifier annotation to class, and also use @qualifier in setter or constructor, \u0026hellip;etc   Prefer constructor injection @resource and @inject are similar to @autowired, but @autowired is very powerful, so use @autowired Specializations of @component annotations  @Controller @Service @Repository @Configuration @SpringBootApplication(scanBasePackageClasses = {default.class, abc.class}) - scans through the package and puts any dependency injection components into application context @RestController \u0026hellip;.. many others   what if you import a dependency and you have to create object from there, you cannot add @component annotation dependency package  Create a new config class, which has methods to return objects from the external dependency the new config class must have @Configuration annotation and methods must have @Bean configuration names of the methods can be used for object variable names   use @Value annotation to access variables from .properties or .yaml files an external config file takes more preference over internal config(application.properties) **Profiles: **A spring application can be configure to behave differently in different environments using profiles  ex environments: dev, test, prod provide in application.properties:  spring.profiles.active: book, dev   you can also use particular beans in particular environments!  just\tuse @Profile(\u0026ldquo;envName\u0026rdquo;), can accepts bool, !envName   @Conditional annotation, include or exclude beans based on arbitrary conditions  @ConditionalOnClass, OnProperty, OnMissingBean ..etc configure bean based on presence of application property =\u0026gt; @ConditionalOnProperty     In @Configuration classes, when we try to create same bean again from some method, spring still returns the cached bean only.  Caching does not happen when we use @Component annotation   Always use @Configuration Classes  ","date":"Oct 09","permalink":"https://rahilrehan.github.io/post/dependecy-injection-spring/","tags":["java"],"title":"Dependency Injection - Spring"},{"categories":["microservices","backend"],"contents":"   Microservices Concepts (Using Java technologies)  In microservices we can have multiple services running, and each service can have multiple instances as well.\nProduct service: browse products using rest api Order service: places order Inventory service: checks if product is available in inventory Notification service:\n   Discovery Service   Each service can have multiple instances running and they need to discover each other. As we cannot particularly specify the service as they are multiple instances, referring to different service needs to be generic. Referring to one service means to refer to available services. In java we can use spring cloud netflix eureka     Centralized configuration   If we change a config variable in code, we need to make change to code, compile and re-deploy it again. If we have multiple instances of same service then it becomes hard as we need to take down those services as well . Solution: Use a centralized config server Store all config variables of different services in different files in a git repository or local store. Whenever there is change in these files, config server will have new config variables. Now to refresh all the config variables in runtime, you need to call to some api actuator which will refresh the config variables in that service and all its instances. In Java Central config server with automatic refresh     Storing secrets in vault   usernames, passwords, database links etc have to be hidden from configuration We have to install vault in our system or via docker, starting vault will start a server as well. Save all the secrets in vault. In Java we can use Spring starter vault config to use secrets in our code. It\u0026rsquo;s enough just to connect to vault server and all the secrets are made available to the service.     Message Broker   One service might depend on other service, change in config variable of one service may effect the other. We can use message broker like RabbitMQ, which broadcast that there is some change in config to other services which are subscribed to that service which has changes. RabbitMQ must be installed on the host system and runs on some host and port. RabbitMQ in infra?     API gateway   We may have different services in our application. Each service may handle different endpoints. API gateway, receives a uri request from clients. It redirects the client to correct service. It acts like a central endpoint distributer. We can attach load balancers to each service as well. Authentication, monitoring and rete limiting can also be taken care here. API gateway is also a service and should be present in discovery service. In Java, spring cloud gateway     Sercuring server with authentication and authorization   Run keycloak on host machine, it will start at some port token relay:  If authentication is done by token, using keycloak as we will be authorizing at api gateway, we need to send this token to the respective gateway as well.   In Java, use Keycloak     Resilience   Order service asynchronously communicates with Inventory service Inventory service can go down, so we need to make it resilient RequestInterceptor:  When one service is speaking to other, authentication token is not sent. Because, it is not token relay mechanism. For passing auth token, we need to get the token and append it to authorization bearer in the request header and then send the request to service.   Definition: watch for service outages and network latencies and temporarily stop the service until service starts functioning normally again . In Java, Resilience4g or hystrix(netflix - not maintained right now)     Event driven microservices architecture   When order is placed, order service broadcasts message to notification service via RabbitMQ. Use rabbitMQ binders to listen for events  output binders: to send notifications input binders: to receive notifications       Distributed tracing   microservices pattern allows us to track the requests from one microservice to other. We give unique id along the journey of the request each request has same trace id along its journey but when there is a circuit breaker in between, trace id changes as circuit breaker spawns a new thread. But there is a workaround to keep our trace id same(traceableExecuterService in Java) In java, we use spring cloud sleuth and zipkin     Centralized logging   logs are all over different services place all logs in a centralized manner First we need to use some logging library at each service like log4J or logback beware of security issues while logging In java (ELK stack is popular -\u0026gt; elastic search, logstash and kibana)  logstash: application services send logs to logstash over tcp. these logs are then sent from logstash to elastic search.  phases:\t(configure in logstash.conf)  input: from services using tcp or ftp or rabbitMQ filter: filter logs output: send to elastic search     Elastic search(search engine implementation in java): Used to store logs  Each service has its own index in elastic search   Kibana: Visualize, Query and filter elastic search data       End   Do not use microservice architecture unless there is a need. Monoliths are best in most cases.  ","date":"Oct 09","permalink":"https://rahilrehan.github.io/post/microservices-concepts-java/","tags":["java"],"title":"Microservices Concepts - Java"},{"categories":["concepts"],"contents":" The art of a good night\u0026rsquo;s sleep is knowing you will not get woken by a support call and the piece of mind from being able to confidently change your software in an always moving market. - Nic Jackson change in code can have undesirable effect on the other parts, tests helps in making the process of changing code in future easy testing pyramid: unit testing(bottom), service/integration(middle), ui/end-end(top)  test cases should decrease as you go from bottom to top        Approach   Just write test first (use expected function) Run and fail the test Write minimal code for the test to run and fail Write minimal code to make test pass Test same function with different values Make sure all tests are passing Tests for base cases Refactor both code and tests     Features and scenarios   Given a feature, break it down to scenarios. Each feature is a user story  Example Feature: As a user when I call the search endpoint, I would like to receive a list of kittens Break it down to scenarios  1st Scenario: Invalid query\nGiven I have no search criteria\nWhen I call the search endpoint\nThen I should receive a bad request message and so\u0026hellip; on number of different scenarios         Uncle bobs, rules of unit tests   First law: You may not write production code until you have written a failing unit test Second law: You may not write more of a unit test than is sufficient to fail, and not compiling is failing Third law: You may not write more production code than is sufficient to pass the currently failing test     Naming   my convention: TestNameReturnSomethingWhenSomethingHappens  example: TestDogHandlerReturnsBadRequestWhenNoSearchCriteriaIsSent       AAA format for testing - Arrange, Act, Assert   I always try to follow this pattern for clean code  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  public class CalculatorTest{ public void sumOfTwoNumbers(){ //Arrange \tdouble first = 10; double second = 20; var Calc = new Calculator(); //Act \tdouble result = Calc.Sum(first, second); //Assert \tAssert.Equal(30, result); } }      concepts   Idempotency Side effects A stub is a fake class that comes with preprogrammed return values. It’s injected into the class under test to give you absolute control over what’s being tested as input. A typical stub is a database connection that allows you to mimic any scenario without having a real database. A mock is a fake class that can be examined after the test is finished for its interactions with the class under test. For example, you can ask it whether a method was called or how many times it was called. Typical mocks are classes with side effects that need to be examined, e.g. a class that sends emails or sends data to another external service. Learn mocking - https://semaphoreci.com/community/tutorials/stubbing-and-mocking-with-mockito-2-and-junit Wrapper: something which hides implementation of some other code or internally uses other code.  ","date":"Oct 09","permalink":"https://rahilrehan.github.io/post/test-driven-development-notes/","tags":["testing"],"title":"Test Driven Development - Notes"},{"categories":null,"contents":"","date":"Jan 01","permalink":"https://rahilrehan.github.io/articles/","tags":null,"title":"Articles"}]